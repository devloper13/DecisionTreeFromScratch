{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "from copy import deepcopy\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train(location):\n",
    "    location = '~/Documents/SMAI/Assignment3/' + location\n",
    "    dataframe = pd.read_csv(location,header=None)\n",
    "    #dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "    train  = dataframe[:int(0.8*len(dataframe))]\n",
    "    test = dataframe[int(0.8*len(dataframe)):]\n",
    "    return test,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train_with_header(location):\n",
    "    location = '~/Documents/SMAI/Assignment3/' + location\n",
    "    dataframe = pd.read_csv(location)\n",
    "    #dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "    train  = dataframe[:int(0.8*len(dataframe))]\n",
    "    test = dataframe[int(0.8*len(dataframe)):]\n",
    "    return dataframe,test,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(location):\n",
    "    location = '~/Documents/SMAI/Assignment3/' + location\n",
    "    dataframe = pd.read_csv(location)\n",
    "    X = dataframe.values[:,:-1]\n",
    "    Y = dataframe.values[:,-1]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "PCA is used for dimensionality reduction.\n",
    "\n",
    "<b>Algorithm</b>\n",
    "\n",
    "1. Standardize the data.\n",
    "2. Obtain the Eigenvectors and Eigenvalues from the covariance matrix or correlation matrix, or perform Singular Vector Decomposition.\n",
    "3. Sort eigenvalues in descending order and choose the k eigenvectors that correspond to the k largest eigenvalues where k is the number of dimensions of the new feature subspace (k≤d).\n",
    "4. Construct the projection matrix W from the selected k eigenvectors.\n",
    "5. Transform the original dataset X via W to obtain a k-dimensional feature subspace Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X):\n",
    "    Z = np.array(X.copy())\n",
    "    #Standardize\n",
    "    for col in range(0,Z.shape[1]):\n",
    "        Z.T[col] = (Z.T[col] - np.mean(Z.T[col]))/np.std(Z.T[col]) \n",
    "    #print(Z)\n",
    "    #Find Covariance\n",
    "    \n",
    "    cov = np.cov(Z.T.astype(float))\n",
    "    eigval,eigvect = LA.eig(cov)\n",
    "    #print(eigval)\n",
    "    #Sort eigen values\n",
    "    eigvalvect = [[np.abs(eigval[i]),eigvect.T[i]] for i in range(0,eigval.shape[0])]\n",
    "    #print(eigvalvect)\n",
    "    eigvalvect.sort(key=lambda x:x[0],reverse=True)\n",
    "    neweigvect = []\n",
    "    for i in range (0,eigval.shape[0]):\n",
    "        neweigvect.append(eigvalvect[i][1])\n",
    "    neweigvect = np.array(neweigvect) #ordered eigen vector\n",
    "    \n",
    "    #Finding K with 10% error\n",
    "    eigvalsum = sum(eigval)\n",
    "    s=0\n",
    "    k=0\n",
    "\n",
    "    for i in range(0,eigval.shape[0]):\n",
    "        s+=eigvalvect[i][0]/eigvalsum\n",
    "        if s < 0.9:\n",
    "            k+=1  \n",
    "        #print(s)    \n",
    "    #print(k+1)\n",
    "    \n",
    "    '''\n",
    "    eignormlist = []\n",
    "    Klist = []\n",
    "    for i in range(0,eigval.shape[0]):\n",
    "        eignormlist.append(eigvalvect[i][0]/eigvalsum)\n",
    "        k+=1\n",
    "        Klist.append(k)\n",
    "    plt.plot(Klist,eignormlist,c='r')\n",
    "    plt.show()\n",
    "    '''\n",
    "    #print(X.shape)\n",
    "    #print(np.array(neweigvect[:k+1]).shape)\n",
    "    projected_data = Z.dot(np.array(neweigvect[:k+1]).T)\n",
    "    #print(neweigvect[:K+1])\n",
    "    #print(projected_data)\n",
    "    return(projected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "K-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. Data points are clustered based on feature similarity. The results of the K-means clustering algorithm are:\n",
    "\n",
    "The centroids of the K clusters, which can be used to label new data\n",
    "Labels for the training data (each data point is assigned to a single cluster)\n",
    "\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Assign random points to the k clusters.\n",
    "2. For a data point, find it's distance from eack k clusters.\n",
    "3. Assign the datapoint to it's nearest cluster.\n",
    "4. Repeat steps 2 and 3 until no assignment of datapoints to clusters changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(data,k):\n",
    "    KPoints = {}\n",
    "    Kval = {}\n",
    "    KPointsRowNum = {}\n",
    "    for i in range(0,k):\n",
    "        KPoints[i] = []\n",
    "        KPointsRowNum[i] = []\n",
    "        Kval[i] = []\n",
    "        \n",
    "    #initialize clusters at random points (at some given point)\n",
    "    for key in Kval:\n",
    "        row = random.randint(0,data.shape[0])\n",
    "        for j in data[row]:\n",
    "            Kval[key].append(random.uniform(0,1))  \n",
    "            #Kval[key].append(j)  #A random point in the dataset is the cluster's position\n",
    "    print(\"C-1\")\n",
    "    #for each row\n",
    "    #  find the distane to each cluster\n",
    "    #  the closest cluster (least distance gets the row)\n",
    "    \n",
    "    #for each cluster \n",
    "    #  find the mean of the points in that cluster\n",
    "    #  change the position of the cluster\n",
    "    \n",
    "    KPointsRowNumCopy = {}\n",
    "    count=1\n",
    "    #while count<=20:\n",
    "    while KPointsRowNumCopy != KPointsRowNum:\n",
    "        print(count)\n",
    "        KPointsRowNumCopy = deepcopy(KPointsRowNum)\n",
    "        for K in KPoints:\n",
    "            KPoints[K] = []\n",
    "            KPointsRowNum[K] = []\n",
    "        #print(\"C0\")\n",
    "        \n",
    "        for row in range(0,data.shape[0]):\n",
    "            \n",
    "            distlist = []\n",
    "            for K in Kval:\n",
    "                center = Kval[K]\n",
    "                #data[row] and center\n",
    "                dist = 0\n",
    "                for attribute in range(0,len(data[row])):\n",
    "                    dist+=(pow(abs(data[row][attribute] - center[attribute]),2))\n",
    "                dist=math.sqrt(dist)\n",
    "                distlist.append(dist)\n",
    "            minclust = np.argmin(distlist)\n",
    "            KPoints[minclust].append(data[row])\n",
    "            KPointsRowNum[minclust].append(row)\n",
    "            \n",
    "        #print(\"C1\")\n",
    "        \n",
    "        for K in KPoints:\n",
    "            mat = np.array(KPoints[K]).T\n",
    "            for i in range(0,len(Kval[K])):\n",
    "                Kval[K][i] = np.sum(mat[i])/len(mat[i])\n",
    "        #print(\"C2\")\n",
    "        \n",
    "        count+=1\n",
    "    return KPointsRowNum \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLabel(CalculatedCluster,NewData,Y):\n",
    "    clusterLabelCount = {}\n",
    "    clusterLabel = {}\n",
    "    clusterDataSize = {}\n",
    "    distinctLabels = np.unique(np.array(Y))\n",
    "    for key in CalculatedCluster:\n",
    "        #key is some cluster here.\n",
    "        clusterLabelCount[key] = {}\n",
    "        clusterLabel[key] = ''\n",
    "        #clusterDataSize has the count of element in every cluster\n",
    "        clusterDataSize[key] = len(CalculatedCluster[key])\n",
    "        \n",
    "        for lab in distinctLabels:\n",
    "            #will have count of every label in a cluster.To be used to find ratio and assign a cluster name .\n",
    "            clusterLabelCount[key][lab] = 0\n",
    "    \n",
    "    for key in CalculatedCluster:\n",
    "        for row in CalculatedCluster[key]:\n",
    "            clusterLabelCount[key][Y[row]]+=1\n",
    "        clusterLabel[key] = sorted(clusterLabelCount[key].items(),key = lambda arg:arg[1],reverse=True)[0][0]\n",
    "    \n",
    "    #print(clusterLabel)  #Adds a label to a cluster\n",
    "    #print(clusterLabelCount)  #Has the count of all data points in cluster\n",
    "    \n",
    "    \n",
    "    return(clusterLabel,clusterLabelCount,clusterDataSize)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic Regression measures the relationship between the dependent variable (our label, what we want to predict) and the one or more independent variables (our features), by estimating probabilities using it’s underlying logistic function.\n",
    "\n",
    "These probabilities must then be transformed into binary values in order to actually make a prediction. This is the task of the logistic function, also called the sigmoid function. The Sigmoid-Function is an S-shaped curve that can take any real-valued number and map it into a value between the range of 0 and 1, but never exactly at those limits. This values between 0 and 1 will then be transformed into either 0 or 1 using a threshold classifier.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Initially, random slopes with respect to number of features is considered. It could be any number.<br><br>\n",
    "\n",
    "2. Another matrix is considered which is the collection of features and it's values. This, with the slopes above tells you about a random line on a 2D plane. We have to use this line and the data pints in the data space to fit the line in such a away that it seperates two classes as much as possible<br><br>\n",
    "\n",
    "3. Use Sigmoid Function to convert any numbers to probabilities<br><br>\n",
    "\n",
    "4. Using gradient descent, we can minimize the error such that our slope that seperates our classes.\n",
    "   We continur this until our error funcion hits a minima.<br><br>\n",
    "5. Now we can test our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def sigmoid(B,X):\n",
    "    return 1/(1+np.exp(-1*(X.dot(B))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "$\\beta_i = \\beta_i - \\alpha\\ast\\dfrac{1}{m}\\sum_{m \\in M}(\\beta_i^TX_m - Y)X_i $ <br>\n",
    "\n",
    "where $X_i$ is the gradient, $\\beta_i^TX$ is the hypothesis, $Y$ is the true value and $\\beta_i$ is the slope of the $i^{th}$ feature. This step updates the slope by calculating the new slope by minimizing cost by differentiating one of the cost functions above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def gradient_descent(X,B,Y,alpha):\n",
    "    m = len(Y)\n",
    "    cost = 0\n",
    "    for i in range(0,500):\n",
    "        #print(B)\n",
    "        B -= alpha*(1/m)*(X.T.dot((sigmoid(B,X) - Y)))/2\n",
    "        #cost = cost_function(X,B,Y)\n",
    "        #print(cost)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def predictLinear(dataframe,test,target,B,multi=False,threshold=0.5):\n",
    "    X = []\n",
    "    x0 = np.ones(test.shape[0])\n",
    "    columns = list(test.columns)\n",
    "    columns.pop(0)\n",
    "    X.append(list(x0))\n",
    "    for col in columns:\n",
    "        if col!= target:\n",
    "            #print(col)\n",
    "            normalized_col = list(((test[col].values) - np.mean(dataframe[col].values))/np.std(dataframe[col].values))\n",
    "            X.append(normalized_col)\n",
    "    \n",
    "    X = np.array(X).T\n",
    "    Y = np.array(test[target].values)\n",
    "    if multi is True:\n",
    "        predicted_y = sigmoid(B,X)\n",
    "    else:\n",
    "        predicted_y = sigmoid(B,X)>=threshold\n",
    "    return X,predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def LogisticRegressionFit(dataframe,test,train,target):\n",
    "    #get X matrx which consists all features\n",
    "    X = []\n",
    "    x0 = np.ones(train.shape[0])\n",
    "    columns = list(train.columns)\n",
    "    columns.pop(0)\n",
    "    X.append(list(x0))\n",
    "    for col in columns:\n",
    "        if col!= target:\n",
    "            #print(col)\n",
    "            normalized_col = list(((train[col].values) - np.mean(dataframe[col].values))/np.std(dataframe[col].values))\n",
    "            X.append(normalized_col)\n",
    "    \n",
    "    X = np.array(X).T\n",
    "    #X = np.array(X)\n",
    "    B = np.array(np.zeros(len(columns)))\n",
    "    Y = np.array(train[target].values)\n",
    "    alpha = 0.1\n",
    "    #B = Y.T.dot(np.linalg.inv(X.T.dot(X)).dot(X.T))\n",
    "    #print(X.shape,B.shape,Y.shape)\n",
    "    B = gradient_descent(X,B,Y,alpha)\n",
    "    return(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction (Binary label)\n",
    "\n",
    "The function <b>BinaryMeasure()</b> is the function that <b>predicts</b> the value for a test set. \n",
    "\n",
    "#### Formula to calculate Accuracy, Precision, Recall and F-Score:\n",
    "\n",
    "<b>Accuracy</b> = $\\dfrac{TP + TN}{TP+TN+FP+FN}$ <br><br>\n",
    "<b>Precision</b> = $\\dfrac{TP}{TP+FP}$<br><br>\n",
    "<b>Recall</b> = $\\dfrac{TP}{TP+FN}$<br><br>\n",
    "<b>F-Score</b> = $\\dfrac{2}{(\\dfrac{1}{Recall}+\\dfrac{1}{Precision})}$<br><br>\n",
    "\n",
    "where <b>TP</b> = True Positive,<br><b>TN</b> = True Negative,<br><b>FP</b> = False Positive,<br><b>FN</b> = False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryMeasure(predicted_y,test,target,multi=False,threshold=0.5):\n",
    "    j = 0\n",
    "    TN=0\n",
    "    TP=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    #print(test[target].values)\n",
    "    if multi is True:\n",
    "        target_col = (test[target].values)\n",
    "        for i in predicted_y:\n",
    "            if i == target_col[j]:\n",
    "                TP+=1\n",
    "            j+=1\n",
    "        accuracy = TP/len(test[target])\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "    else:\n",
    "        target_col = (test[target].values)>=threshold\n",
    "        #print(target_col)\n",
    "        #print(predicted_y,target_col)\n",
    "        for i in predicted_y:\n",
    "            #print(j,target)\n",
    "            if i==0 and i == target_col[j]:\n",
    "                TN+=1\n",
    "            elif i==0 and i!= target_col[j]:\n",
    "                FN+=1\n",
    "            elif i==1 and i == target_col[j]:\n",
    "                TP+=1\n",
    "            elif i==1 and i!= target_col[j]:\n",
    "                FP+=1\n",
    "            j+=1\n",
    "    \n",
    "        #print(TP,TN,FP,FN)\n",
    "        accuracy =  (TP+TN)/(TP+TN+FP+FN)\n",
    "        precision = (TP)/(TP+FP+np.finfo(float).eps)\n",
    "        recall = (TP)/(TP+FN+np.finfo(float).eps)\n",
    "        #fscore = 2/((1/precision)+(1/recall))\n",
    "    return accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   K- Nearest Neighbour (KNN)\n",
    "KNN is one of the most simplest to implement algorithms in Machine Learning. It deals with calculating       distance (of a new data point) with respect to all other data points and finds K nearest neighbout to classify in of the labels.\n",
    "\n",
    "An advantage of KNN is that there is no actual training done unlike other machine learning algorithms. More details mentioned in the algorithm below.\n",
    "\n",
    "### Algorithm\n",
    "1. For every new data point, find the distance between each anad every other already existing data points and    store in a list. The distance can be found by minkowski measure which is discussed in the next segment.<br><br>\n",
    "\n",
    "2. Once distance of a data point from all other data points is found, find those 'K' elements which are          nearest to the data point in question. This can be found by sorting the list of distances. The most            efficient way to sort is using a heap. For simplicity we have used a list.<br><br>\n",
    "\n",
    "3. Among the 'K' nearest points, find the most frequently occuring label and classify the unknown data point      to that label.\n",
    "\n",
    "The below function <b>KNN()</b> does the above mentioned steps. \n",
    "\n",
    "### Minkowski Distance\n",
    "\n",
    "The minkowski distance is of the form : $(\\sum_{i \\in R}|x_i - t_i|^{p})^{1/p}$ where <b>R</b> is a row which represents a data point and <b>i</b> is each field in the row, <b>x</b> is an already data point and <b>t</b> is a new data point to be classified.\n",
    "\n",
    "It is important to note that Minkowski is a generalized distnace formula.The value <b>p</b> defines which distance is used. when <b>p</b> equals 1, it is known as <b>Euclidian Distance</b>.\n",
    "\n",
    "When <b>p</b> equals 2, it is known as <b>Manhattan distance</b>. We have used only these two measures however there are many more distnace metrics out of the Minkowski distance. <b>minkowski_predict</b> calculates the above expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN KNN\n",
    "'''\n",
    "def minkowski_predict(test_row,train_row,power,target):\n",
    "    dist = 0\n",
    "    #print(test_row,train_row,power,target)\n",
    "    for attribute in range(0,len(test_row)):\n",
    "        if attribute != target:\n",
    "            dist+=(pow(abs(test_row[attribute] - train_row[attribute]),power))\n",
    "    return pow(dist,1/power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN KNN\n",
    "'''\n",
    "def getsecond(item):\n",
    "    return item[1]\n",
    "\n",
    "\n",
    "def KNN(test,train,K,dist_measure,target):\n",
    "    unique_values = np.unique(train.values[:,target])\n",
    "    maxval = -1\n",
    "    winner = None\n",
    "    class_dict = {}\n",
    "    for classVal in unique_values:\n",
    "        class_dict[classVal] = 0\n",
    "  \n",
    "    if dist_measure == 'euclid':\n",
    "        power = 2\n",
    "    elif dist_measure == 'man':\n",
    "        power = 1\n",
    "    predicted = []\n",
    "    for test_row in test.values:\n",
    "        #print(test_row)\n",
    "        knn = []\n",
    "        maxval = -1\n",
    "        winner = None\n",
    "        for train_row in train.values:\n",
    "            #print(train_row)\n",
    "            #print(test_row)\n",
    "            y = minkowski_predict(test_row,train_row,power,target)\n",
    "            #print(y)\n",
    "            knn.append((train_row[target],y))\n",
    "        knn.sort(key = getsecond)\n",
    "        \n",
    "        #print(knn)\n",
    "        for i in range(0,K):\n",
    "            class_dict[knn[i][0]]+=1\n",
    "            #if class_dict[knn[i][0]] > maxval:\n",
    "            #    winner = knn[i][0]\n",
    "            #    maxval = class_dict[knn[i][0]]\n",
    "        winner = max(class_dict.items(),key=operator.itemgetter(1))[0]    \n",
    "        predicted.append(winner)\n",
    "        #print(class_dict)\n",
    "        for classVal in unique_values:\n",
    "            class_dict[classVal] = 0\n",
    "    return predicted        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'intrusion_detection/data.csv'\n",
    "X,Y = getXY(location)\n",
    "NewData = PCA(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "#Continued from part-1\n",
    "CalculatedCluster = KMeans(NewData,5)\n",
    "\n",
    "#print(len(CalculatedCluster[0]))\n",
    "#print(len(CalculatedCluster[1]))\n",
    "#print(len(CalculatedCluster[2]))\n",
    "#print(len(CalculatedCluster[3]))\n",
    "#print(len(CalculatedCluster[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Cluster Purity\n",
      "==========================\n",
      "dos\n",
      "0.5543831168831169\n",
      "\n",
      "\n",
      "probe\n",
      "0.62625250501002\n",
      "\n",
      "\n",
      "dos\n",
      "0.9795308187672493\n",
      "\n",
      "\n",
      "normal\n",
      "0.8495932180214671\n",
      "\n",
      "\n",
      "dos\n",
      "0.9937524404529481\n",
      "\n",
      "\n",
      "Total Purity:  0.8489479158332667\n"
     ]
    }
   ],
   "source": [
    "clusterLabel,clusterLabelCountKmeans,clusterDataSize = findLabel(CalculatedCluster,NewData,Y)\n",
    "#print(clusterLabelCount)\n",
    "maxkmeans=0\n",
    "totalpoints=0\n",
    "print(\"Individual Cluster Purity\")\n",
    "print(\"==========================\")\n",
    "for key in clusterLabel:\n",
    "    print(clusterLabel[key])\n",
    "    print(clusterLabelCountKmeans[key][clusterLabel[key]]/clusterDataSize[key])\n",
    "    maxkmeans+=clusterLabelCountKmeans[key][clusterLabel[key]]\n",
    "    print(\"\\n\")\n",
    "#print(CalculatedCluster)\n",
    "for key in clusterDataSize:\n",
    "    totalpoints+=clusterDataSize[key]\n",
    "puritykmeans = maxkmeans/totalpoints\n",
    "print(\"Total Purity: \",puritykmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Cluster Purity\n",
      "==========================\n",
      "dos\n",
      "1.0\n",
      "\n",
      "\n",
      "normal\n",
      "0.6553542009884679\n",
      "\n",
      "\n",
      "normal\n",
      "0.9886221728874706\n",
      "\n",
      "\n",
      "normal\n",
      "0.39592015792937046\n",
      "\n",
      "\n",
      "normal\n",
      "0.5106382978723404\n",
      "\n",
      "\n",
      "Total Purity:  0.7853828306264501\n"
     ]
    }
   ],
   "source": [
    "#PCA, X and Y are defined from PArt-1. Run Part-1 before running this\n",
    "gmm = mixture.GaussianMixture(n_components=5)\n",
    "gmm.fit(NewData)\n",
    "labels = gmm.predict(NewData)\n",
    "dictrowgmm = {}\n",
    "for i in range(0,5):\n",
    "    dictrowgmm[i] = []\n",
    "for i in range(0,len(labels)):\n",
    "    dictrowgmm[labels[i]].append(i)\n",
    "\n",
    "clusterLabel,clusterLabelCountGmm,clusterDataSize = findLabel(dictrowgmm,NewData,Y) \n",
    "#print(clusterLabelCount)\n",
    "maxGmm=0\n",
    "totalpoints=0\n",
    "print(\"Individual Cluster Purity\")\n",
    "print(\"==========================\")\n",
    "for key in clusterLabel:\n",
    "    print(clusterLabel[key])\n",
    "    print(clusterLabelCountGmm[key][clusterLabel[key]]/clusterDataSize[key])\n",
    "    maxGmm+=clusterLabelCountGmm[key][clusterLabel[key]]\n",
    "    print(\"\\n\")\n",
    "#print(CalculatedCluster)\n",
    "for key in clusterDataSize:\n",
    "    totalpoints+=clusterDataSize[key]\n",
    "purityGmm = maxGmm/totalpoints\n",
    "print(\"Total Purity: \",purityGmm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Cluster Purity\n",
      "==========================\n",
      "normal\n",
      "0.5346352395053824\n",
      "\n",
      "\n",
      "probe\n",
      "1.0\n",
      "\n",
      "\n",
      "r2l\n",
      "0.6666666666666666\n",
      "\n",
      "\n",
      "normal\n",
      "1.0\n",
      "\n",
      "\n",
      "normal\n",
      "1.0\n",
      "\n",
      "\n",
      "Total Purity:  0.5347227778222258\n"
     ]
    }
   ],
   "source": [
    "#PCA, X and Y are defined from PArt-1. Run Part-1 before running this\n",
    "clt = AgglomerativeClustering(linkage='single', \n",
    "                              affinity='euclidean', \n",
    "                              n_clusters=5)\n",
    "model = clt.fit(NewData)\n",
    "labels = model.labels_\n",
    "dictrowAgg = {}\n",
    "for i in range(0,5):\n",
    "    dictrowAgg[i] = []\n",
    "for i in range(0,len(labels)):\n",
    "    dictrowAgg[labels[i]].append(i)\n",
    "\n",
    "clusterLabel,clusterLabelCountAgg,clusterDataSize = findLabel(dictrowAgg,NewData,Y) \n",
    "#print(clusterLabelCount)\n",
    "maxAgg=0\n",
    "totalpoints=0\n",
    "print(\"Individual Cluster Purity\")\n",
    "print(\"==========================\")\n",
    "for key in clusterLabel:\n",
    "    print(clusterLabel[key])\n",
    "    print(clusterLabelCountAgg[key][clusterLabel[key]]/clusterDataSize[key])\n",
    "    maxAgg+=clusterLabelCountAgg[key][clusterLabel[key]]\n",
    "    print(\"\\n\")\n",
    "#print(CalculatedCluster)\n",
    "for key in clusterDataSize:\n",
    "    totalpoints+=clusterDataSize[key]\n",
    "purityAgg = maxAgg/totalpoints\n",
    "print(\"Total Purity: \",purityAgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Make sure to run all the above code first.\n",
    "labels = ['K-Means', 'GMM', 'Agglomerative']\n",
    "sizes = [puritykmeans,purityGmm,purityAgg]\n",
    "colors = ['#ff6666', '#ffcc99', '#99ff99']\n",
    "clusterLabelCount = {}\n",
    "\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%',colors=colors_in,radius = 1.5,startangle=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally PCA is used for continuous variables. This is becuase we need to calculate strandard deviation and mean to standardize the data. If we use this in a categorical variable, it becomes difficult to standardize the data. Thus the challenge here is to find a mechanism to make these a continuous types maybe by uisng distance formulas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "location = 'AdmissionDataset/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "target = 'Chance of Admit'\n",
    "slopeValues = LogisticRegressionFit(dataframe,test,train,target)\n",
    "X,predicted_y = predictLinear(dataframe,test,target,slopeValues)\n",
    "accuracy,precision,recall = BinaryMeasure(predicted_y,test,target)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Accuracy =  0.9444444444444444\n",
      "Precision =  0.9418604651162791\n",
      "Recall =  1.0\n"
     ]
    }
   ],
   "source": [
    "location = 'AdmissionDataset/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "test = pd.DataFrame(np.delete(test.values,0,1))\n",
    "train = pd.DataFrame(np.delete(train.values,0,1))\n",
    "K = 7\n",
    "target = 7\n",
    "#print(test.values)\n",
    "train.values.T[-1] = np.array(train.values.T[-1])>=0.5\n",
    "test.values.T[-1] = np.array(test.values.T[-1])>=0.5\n",
    "#print(test.values.T[-1])\n",
    "predicted_y = KNN(test,train,K,'euclid',target)\n",
    "#print(predicted_y)\n",
    "#test.values[target] = np.array(test.values[target])>=0.5\n",
    "accuracy,precision,recall = BinaryMeasure(np.array(predicted_y)>=0.5,test,target)\n",
    "#print(\"Robot1\")\n",
    "print(\"===================================\")\n",
    "print(\"Accuracy = \",accuracy)\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "location = 'AdmissionDataset/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "target = 'Chance of Admit'\n",
    "problist = []\n",
    "precisionlist = []\n",
    "recallist = []\n",
    "prob = 1\n",
    "while prob < 10:\n",
    "    slopeValues = LogisticRegressionFit(dataframe,test,train,target)\n",
    "    X,predicted_y = predictLinear(dataframe,test,target,slopeValues,False,prob/10)\n",
    "    accuracy,precision,recall = BinaryMeasure(predicted_y,test,target,False,prob/10)\n",
    "    problist.append(prob/10)\n",
    "    precisionlist.append(precision)\n",
    "    recallist.append(recall)\n",
    "    prob+=1\n",
    "plt.plot(problist,recallist,label='recall')\n",
    "plt.plot(problist,precisionlist,label='precision')\n",
    "plt.xlabel = 'threshold'\n",
    "plt.ylabel = 'measure'\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important criteria to choose a threshold is to clearly divide the values such that they can be classified in a binary way. Thus we must choose a threshold with least bias i.e middle most of any range. Since probabilities range between 0 and 1, 0.5 is a good threshold to choose (which is also been chosen in this project)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3, 1: 4, 2: 5, 3: 6, 4: 7, 5: 8, 6: 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5374149659863946\n"
     ]
    }
   ],
   "source": [
    "location = 'wine-quality/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "#print(test)\n",
    "testcopy = test.copy()\n",
    "traincopy = train.copy()\n",
    "target = 'quality'\n",
    "unique_class = np.unique(np.array(train[target]))\n",
    "labpred = []\n",
    "labdict = {}\n",
    "true_predicted = []\n",
    "z = 0\n",
    "for key in unique_class:\n",
    "    labdict[z] = key\n",
    "    z+=1\n",
    "print(labdict)\n",
    "for c in unique_class:\n",
    "    train[target] = (train[target].values) == c\n",
    "    test[target] = (test[target].values) == c\n",
    "    slopeValues = LogisticRegressionFit(dataframe,test,train,target)\n",
    "    #print(slopeValues)\n",
    "    X,predicted_y = predictLinear(dataframe,test,target,slopeValues,True)\n",
    "    labpred.append(predicted_y)\n",
    "    train = traincopy.copy()\n",
    "    test = testcopy.copy()\n",
    "    #print(predicted_y)\n",
    "    #print(test[target].values)\n",
    "labpred = np.array(labpred)\n",
    "#print(labpred)\n",
    "for row in range(0,len(testcopy[target])):\n",
    "    true_predicted.append(labdict[(np.argmax(labpred[:,row]))])\n",
    "#print(true_predicted)\n",
    "#print(testcopy[target])\n",
    "accuracy,precision,recall = BinaryMeasure(true_predicted,testcopy,target,True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5272108843537415\n"
     ]
    }
   ],
   "source": [
    "location = 'wine-quality/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "#print(test)\n",
    "testcopy = test.copy()\n",
    "traincopy = train.copy()\n",
    "target = 'quality'\n",
    "unique_class = np.unique(np.array(train[target]))\n",
    "labpred = []\n",
    "labdict = {}\n",
    "true_predicted = []\n",
    "z = 0\n",
    "for key in unique_class:\n",
    "    labdict[z] = key\n",
    "    z+=1\n",
    "    \n",
    "for c1_ind in range(0,len(unique_class)):\n",
    "    for c2_ind in range(c1_ind,len(unique_class)):\n",
    "        if unique_class[c1_ind]!=unique_class[c2_ind]:\n",
    "            train = train[(train[target] == unique_class[c1_ind]) | (train[target] == unique_class[c2_ind])]\n",
    "            train = test[(test[target] == unique_class[c1_ind]) | (test[target] == unique_class[c2_ind])]\n",
    "            #print(train)\n",
    "            train[target] = (train[target].values) == unique_class[c1_ind]\n",
    "            test[target] = (test[target].values) == unique_class[c1_ind]\n",
    "            slopeValues = LogisticRegressionFit(dataframe,test,train,target)\n",
    "            X,predicted_y = predictLinear(dataframe,test,target,slopeValues,True)\n",
    "            for val in range(0,len(predicted_y)):\n",
    "                if predicted_y[val] >= 0.5:\n",
    "                    predicted_y[val] = unique_class[c1_ind]\n",
    "                else:\n",
    "                    predicted_y[val] = unique_class[c2_ind]\n",
    "            labpred.append(predicted_y)\n",
    "            train = traincopy.copy()\n",
    "            test = testcopy.copy()\n",
    "            #print(predicted_y)\n",
    "            #print(test[target].values)\n",
    "labpred = np.array(labpred)\n",
    "predarr = []\n",
    "for row in range(0,len(testcopy[target])):\n",
    "    #print(row)\n",
    "    col = []\n",
    "    col.extend(labpred[:,row])\n",
    "    count = max(col,key=col.count)\n",
    "    true_predicted.append(count)\n",
    "    #true_predicted.append(labdict[(np.argmax(labpred[:,row]))]) \n",
    "accuracy,precision,recall = BinaryMeasure(true_predicted,testcopy,target,True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
