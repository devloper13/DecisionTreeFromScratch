{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "from copy import deepcopy\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train(location):\n",
    "    location = '~/Documents/SMAI/Assignment3/' + location\n",
    "    dataframe = pd.read_csv(location,header=None)\n",
    "    #dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "    train  = dataframe[:int(0.8*len(dataframe))]\n",
    "    test = dataframe[int(0.8*len(dataframe)):]\n",
    "    return test,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train_with_header(location):\n",
    "    location = '~/Documents/SMAI/Assignment3/' + location\n",
    "    dataframe = pd.read_csv(location)\n",
    "    #dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "    train  = dataframe[:int(0.8*len(dataframe))]\n",
    "    test = dataframe[int(0.8*len(dataframe)):]\n",
    "    return dataframe,test,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(location):\n",
    "    location = '~/Documents/SMAI/Assignment3/' + location\n",
    "    dataframe = pd.read_csv(location)\n",
    "    X = dataframe.values[:,:-1]\n",
    "    Y = dataframe.values[:,-1]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X):\n",
    "    Z = np.array(X.copy())\n",
    "    #Standardize\n",
    "    for col in range(0,Z.shape[1]):\n",
    "        Z.T[col] = (Z.T[col] - np.mean(Z.T[col]))/np.std(Z.T[col]) \n",
    "    #print(Z)\n",
    "    #Find Covariance\n",
    "    \n",
    "    cov = np.cov(Z.T.astype(float))\n",
    "    eigval,eigvect = LA.eig(cov)\n",
    "    #print(eigval)\n",
    "    #Sort eigen values\n",
    "    eigvalvect = [[np.abs(eigval[i]),eigvect.T[i]] for i in range(0,eigval.shape[0])]\n",
    "    #print(eigvalvect)\n",
    "    eigvalvect.sort(key=lambda x:x[0],reverse=True)\n",
    "    neweigvect = []\n",
    "    for i in range (0,eigval.shape[0]):\n",
    "        neweigvect.append(eigvalvect[i][1])\n",
    "    neweigvect = np.array(neweigvect) #ordered eigen vector\n",
    "    \n",
    "    #Finding K with 10% error\n",
    "    eigvalsum = sum(eigval)\n",
    "    s=0\n",
    "    k=0\n",
    "\n",
    "    for i in range(0,eigval.shape[0]):\n",
    "        s+=eigvalvect[i][0]/eigvalsum\n",
    "        if s < 0.9:\n",
    "            k+=1  \n",
    "        #print(s)    \n",
    "    #print(k+1)\n",
    "    \n",
    "    '''\n",
    "    eignormlist = []\n",
    "    Klist = []\n",
    "    for i in range(0,eigval.shape[0]):\n",
    "        eignormlist.append(eigvalvect[i][0]/eigvalsum)\n",
    "        k+=1\n",
    "        Klist.append(k)\n",
    "    plt.plot(Klist,eignormlist,c='r')\n",
    "    plt.show()\n",
    "    '''\n",
    "    #print(X.shape)\n",
    "    #print(np.array(neweigvect[:k+1]).shape)\n",
    "    projected_data = Z.dot(np.array(neweigvect[:k+1]).T)\n",
    "    #print(neweigvect[:K+1])\n",
    "    #print(projected_data)\n",
    "    return(projected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(data,k):\n",
    "    KPoints = {}\n",
    "    Kval = {}\n",
    "    KPointsRowNum = {}\n",
    "    for i in range(0,k):\n",
    "        KPoints[i] = []\n",
    "        KPointsRowNum[i] = []\n",
    "        Kval[i] = []\n",
    "        \n",
    "    #initialize clusters at random points (at some given point)\n",
    "    for key in Kval:\n",
    "        row = random.randint(0,data.shape[0])\n",
    "        for j in data[row]:\n",
    "            Kval[key].append(random.uniform(0,1))  \n",
    "            #Kval[key].append(j)  #A random point in the dataset is the cluster's position\n",
    "    print(\"C-1\")\n",
    "    #for each row\n",
    "    #  find the distane to each cluster\n",
    "    #  the closest cluster (least distance gets the row)\n",
    "    \n",
    "    #for each cluster \n",
    "    #  find the mean of the points in that cluster\n",
    "    #  change the position of the cluster\n",
    "    \n",
    "    KPointsRowNumCopy = {}\n",
    "    count=1\n",
    "    #while count<=20:\n",
    "    while KPointsRowNumCopy != KPointsRowNum:\n",
    "        print(count)\n",
    "        KPointsRowNumCopy = deepcopy(KPointsRowNum)\n",
    "        for K in KPoints:\n",
    "            KPoints[K] = []\n",
    "            KPointsRowNum[K] = []\n",
    "        #print(\"C0\")\n",
    "        \n",
    "        for row in range(0,data.shape[0]):\n",
    "            \n",
    "            distlist = []\n",
    "            for K in Kval:\n",
    "                center = Kval[K]\n",
    "                #data[row] and center\n",
    "                dist = 0\n",
    "                for attribute in range(0,len(data[row])):\n",
    "                    dist+=(pow(abs(data[row][attribute] - center[attribute]),2))\n",
    "                dist=math.sqrt(dist)\n",
    "                distlist.append(dist)\n",
    "            minclust = np.argmin(distlist)\n",
    "            KPoints[minclust].append(data[row])\n",
    "            KPointsRowNum[minclust].append(row)\n",
    "            \n",
    "        #print(\"C1\")\n",
    "        \n",
    "        for K in KPoints:\n",
    "            mat = np.array(KPoints[K]).T\n",
    "            for i in range(0,len(Kval[K])):\n",
    "                Kval[K][i] = np.sum(mat[i])/len(mat[i])\n",
    "        #print(\"C2\")\n",
    "        \n",
    "        count+=1\n",
    "    return KPointsRowNum \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLabel(CalculatedCluster,NewData,Y):\n",
    "    clusterLabelCount = {}\n",
    "    clusterLabel = {}\n",
    "    clusterDataSize = {}\n",
    "    distinctLabels = np.unique(np.array(Y))\n",
    "    for key in CalculatedCluster:\n",
    "        #key is some cluster here.\n",
    "        clusterLabelCount[key] = {}\n",
    "        clusterLabel[key] = ''\n",
    "        #clusterDataSize has the count of element in every cluster\n",
    "        clusterDataSize[key] = len(CalculatedCluster[key])\n",
    "        \n",
    "        for lab in distinctLabels:\n",
    "            #will have count of every label in a cluster.To be used to find ratio and assign a cluster name .\n",
    "            clusterLabelCount[key][lab] = 0\n",
    "    \n",
    "    for key in CalculatedCluster:\n",
    "        for row in CalculatedCluster[key]:\n",
    "            clusterLabelCount[key][Y[row]]+=1\n",
    "        clusterLabel[key] = sorted(clusterLabelCount[key].items(),key = lambda arg:arg[1],reverse=True)[0][0]\n",
    "    \n",
    "    #print(clusterLabel)  #Adds a label to a cluster\n",
    "    #print(clusterLabelCount)  #Has the count of all data points in cluster\n",
    "    \n",
    "    \n",
    "    return(clusterLabel,clusterLabelCount,clusterDataSize)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def sigmoid(B,X):\n",
    "    return 1/(1+np.exp(-1*(X.dot(B))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def gradient_descent(X,B,Y,alpha):\n",
    "    m = len(Y)\n",
    "    cost = 0\n",
    "    for i in range(0,500):\n",
    "        #print(B)\n",
    "        B -= alpha*(1/m)*(X.T.dot((sigmoid(B,X) - Y)))/2\n",
    "        #cost = cost_function(X,B,Y)\n",
    "        #print(cost)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def predictLinear(dataframe,test,target,B,multi=False):\n",
    "    X = []\n",
    "    x0 = np.ones(test.shape[0])\n",
    "    columns = list(test.columns)\n",
    "    columns.pop(0)\n",
    "    X.append(list(x0))\n",
    "    for col in columns:\n",
    "        if col!= target:\n",
    "            #print(col)\n",
    "            normalized_col = list(((test[col].values) - np.mean(dataframe[col].values))/np.std(dataframe[col].values))\n",
    "            X.append(normalized_col)\n",
    "    \n",
    "    X = np.array(X).T\n",
    "    Y = np.array(test[target].values)\n",
    "    if multi is True:\n",
    "        predicted_y = sigmoid(B,X)\n",
    "    else:\n",
    "        predicted_y = sigmoid(B,X)>=0.5\n",
    "    return X,predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN Logistic REGRESSION\n",
    "'''\n",
    "def LogisticRegressionFit(dataframe,test,train,target):\n",
    "    #get X matrx which consists all features\n",
    "    X = []\n",
    "    x0 = np.ones(train.shape[0])\n",
    "    columns = list(train.columns)\n",
    "    columns.pop(0)\n",
    "    X.append(list(x0))\n",
    "    for col in columns:\n",
    "        if col!= target:\n",
    "            #print(col)\n",
    "            normalized_col = list(((train[col].values) - np.mean(dataframe[col].values))/np.std(dataframe[col].values))\n",
    "            X.append(normalized_col)\n",
    "    \n",
    "    X = np.array(X).T\n",
    "    #X = np.array(X)\n",
    "    B = np.array(np.zeros(len(columns)))\n",
    "    Y = np.array(train[target].values)\n",
    "    alpha = 0.1\n",
    "    #B = Y.T.dot(np.linalg.inv(X.T.dot(X)).dot(X.T))\n",
    "    #print(X.shape,B.shape,Y.shape)\n",
    "    B = gradient_descent(X,B,Y,alpha)\n",
    "    return(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryMeasure(predicted_y,test,target,multi=False):\n",
    "    j = 0\n",
    "    TN=0\n",
    "    TP=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    #print(test[target].values)\n",
    "    if multi is True:\n",
    "        target_col = (test[target].values)\n",
    "        for i in predicted_y:\n",
    "            if i == target_col[j]:\n",
    "                TP+=1\n",
    "            j+=1\n",
    "        accuracy = TP/len(test[target])\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "    else:\n",
    "        target_col = (test[target].values)>=0.5\n",
    "        #print(target_col)\n",
    "        #print(predicted_y,target_col)\n",
    "        for i in predicted_y:\n",
    "            #print(j,target)\n",
    "            if i==0 and i == target_col[j]:\n",
    "                TN+=1\n",
    "            elif i==0 and i!= target_col[j]:\n",
    "                FN+=1\n",
    "            elif i==1 and i == target_col[j]:\n",
    "                TP+=1\n",
    "            elif i==1 and i!= target_col[j]:\n",
    "                FP+=1\n",
    "            j+=1\n",
    "    \n",
    "        #print(TP,TN,FP,FN)\n",
    "        accuracy =  (TP+TN)/(TP+TN+FP+FN)\n",
    "        precision = (TP)/(TP+FP+np.finfo(float).eps)\n",
    "        recall = (TP)/(TP+FN+np.finfo(float).eps)\n",
    "        #fscore = 2/((1/precision)+(1/recall))\n",
    "    return accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN KNN\n",
    "'''\n",
    "def minkowski_predict(test_row,train_row,power,target):\n",
    "    dist = 0\n",
    "    #print(test_row,train_row,power,target)\n",
    "    for attribute in range(0,len(test_row)):\n",
    "        if attribute != target:\n",
    "            dist+=(pow(abs(test_row[attribute] - train_row[attribute]),power))\n",
    "    return pow(dist,1/power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USED IN KNN\n",
    "'''\n",
    "def getsecond(item):\n",
    "    return item[1]\n",
    "\n",
    "\n",
    "def KNN(test,train,K,dist_measure,target):\n",
    "    unique_values = np.unique(train.values[:,target])\n",
    "    maxval = -1\n",
    "    winner = None\n",
    "    class_dict = {}\n",
    "    for classVal in unique_values:\n",
    "        class_dict[classVal] = 0\n",
    "  \n",
    "    if dist_measure == 'euclid':\n",
    "        power = 2\n",
    "    elif dist_measure == 'man':\n",
    "        power = 1\n",
    "    predicted = []\n",
    "    for test_row in test.values:\n",
    "        #print(test_row)\n",
    "        knn = []\n",
    "        maxval = -1\n",
    "        winner = None\n",
    "        for train_row in train.values:\n",
    "            #print(train_row)\n",
    "            #print(test_row)\n",
    "            y = minkowski_predict(test_row,train_row,power,target)\n",
    "            #print(y)\n",
    "            knn.append((train_row[target],y))\n",
    "        knn.sort(key = getsecond)\n",
    "        \n",
    "        #print(knn)\n",
    "        for i in range(0,K):\n",
    "            class_dict[knn[i][0]]+=1\n",
    "            #if class_dict[knn[i][0]] > maxval:\n",
    "            #    winner = knn[i][0]\n",
    "            #    maxval = class_dict[knn[i][0]]\n",
    "        winner = max(class_dict.items(),key=operator.itemgetter(1))[0]    \n",
    "        predicted.append(winner)\n",
    "        #print(class_dict)\n",
    "        for classVal in unique_values:\n",
    "            class_dict[classVal] = 0\n",
    "    return predicted        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'intrusion_detection/data.csv'\n",
    "X,Y = getXY(location)\n",
    "NewData = PCA(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#Continued from part-1\n",
    "CalculatedCluster = KMeans(NewData,5)\n",
    "\n",
    "#print(len(CalculatedCluster[0]))\n",
    "#print(len(CalculatedCluster[1]))\n",
    "#print(len(CalculatedCluster[2]))\n",
    "#print(len(CalculatedCluster[3]))\n",
    "#print(len(CalculatedCluster[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'dos': 0, 'normal': 8, 'probe': 0, 'r2l': 0, 'u2r': 0}, 1: {'dos': 931, 'normal': 12425, 'probe': 1076, 'r2l': 185, 'u2r': 10}, 2: {'dos': 6802, 'normal': 35, 'probe': 62, 'r2l': 0, 'u2r': 0}, 3: {'dos': 1366, 'normal': 540, 'probe': 547, 'r2l': 10, 'u2r': 0}, 4: {'dos': 15, 'normal': 356, 'probe': 628, 'r2l': 2, 'u2r': 0}}\n",
      "normal\n",
      "1.0\n",
      "\n",
      "\n",
      "normal\n",
      "0.8494564845833048\n",
      "\n",
      "\n",
      "dos\n",
      "0.9859399913030874\n",
      "\n",
      "\n",
      "dos\n",
      "0.5546082013804303\n",
      "\n",
      "\n",
      "probe\n",
      "0.6273726273726273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusterLabel,clusterLabelCount,clusterDataSize = findLabel(CalculatedCluster,NewData,Y)\n",
    "print(clusterLabelCount)\n",
    "for key in clusterLabel:\n",
    "    print(clusterLabel[key])\n",
    "    print(clusterLabelCount[key][clusterLabel[key]]/clusterDataSize[key])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "0.42648864333947206\n",
      "\n",
      "\n",
      "normal\n",
      "0.5222701149425287\n",
      "\n",
      "\n",
      "dos\n",
      "1.0\n",
      "\n",
      "\n",
      "normal\n",
      "1.0\n",
      "\n",
      "\n",
      "normal\n",
      "0.9323237103644108\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PCA, X and Y are defined from PArt-1. Run Part-1 before running this\n",
    "gmm = mixture.GaussianMixture(n_components=5)\n",
    "gmm.fit(NewData)\n",
    "labels = gmm.predict(NewData)\n",
    "dictrowgmm = {}\n",
    "for i in range(0,5):\n",
    "    dictrowgmm[i] = []\n",
    "for i in range(0,len(labels)):\n",
    "    dictrowgmm[labels[i]].append(i)\n",
    "\n",
    "clusterLabel,clusterLabelCount,clusterDataSize = findLabel(dictrowgmm,NewData,Y) \n",
    "#print(clusterLabelCount)\n",
    "for key in clusterLabel:\n",
    "    print(clusterLabel[key])\n",
    "    print(clusterLabelCount[key][clusterLabel[key]]/clusterDataSize[key])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "1.0\n",
      "\n",
      "\n",
      "normal\n",
      "0.8461538461538461\n",
      "\n",
      "\n",
      "normal\n",
      "0.5343156883158485\n",
      "\n",
      "\n",
      "probe\n",
      "1.0\n",
      "\n",
      "\n",
      "normal\n",
      "0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PCA, X and Y are defined from PArt-1. Run Part-1 before running this\n",
    "clt = AgglomerativeClustering(linkage='complete', \n",
    "                              affinity='euclidean', \n",
    "                              n_clusters=5)\n",
    "model = clt.fit(NewData)\n",
    "labels = model.labels_\n",
    "dictrowgmm = {}\n",
    "for i in range(0,5):\n",
    "    dictrowgmm[i] = []\n",
    "for i in range(0,len(labels)):\n",
    "    dictrowgmm[labels[i]].append(i)\n",
    "\n",
    "clusterLabel,clusterLabelCount,clusterDataSize = findLabel(dictrowgmm,NewData,Y) \n",
    "#print(clusterLabelCount)\n",
    "for key in clusterLabel:\n",
    "    print(clusterLabel[key])\n",
    "    print(clusterLabelCount[key][clusterLabel[key]]/clusterDataSize[key])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "location = 'AdmissionDataset/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "target = 'Chance of Admit'\n",
    "slopeValues = LogisticRegressionFit(test,train,target)\n",
    "X,predicted_y = predictLinear(test,target,slopeValues)\n",
    "accuracy,precision,recall = BinaryMeasure(predicted_y,test,target)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot1\n",
      "===================================\n",
      "Accuracy =  0.9444444444444444\n",
      "Precision =  0.9418604651162791\n",
      "Recall =  1.0\n"
     ]
    }
   ],
   "source": [
    "location = 'AdmissionDataset/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "test = pd.DataFrame(np.delete(test.values,0,1))\n",
    "train = pd.DataFrame(np.delete(train.values,0,1))\n",
    "K = 7\n",
    "target = 7\n",
    "#print(test.values)\n",
    "train.values.T[-1] = np.array(train.values.T[-1])>=0.5\n",
    "test.values.T[-1] = np.array(test.values.T[-1])>=0.5\n",
    "#print(test.values.T[-1])\n",
    "predicted_y = KNN(test,train,K,'euclid',target)\n",
    "#print(predicted_y)\n",
    "#test.values[target] = np.array(test.values[target])>=0.5\n",
    "accuracy,precision,recall = BinaryMeasure(np.array(predicted_y)>=0.5,test,target)\n",
    "print(\"Robot1\")\n",
    "print(\"===================================\")\n",
    "print(\"Accuracy = \",accuracy)\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3, 1: 4, 2: 5, 3: 6, 4: 7, 5: 8, 6: 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5374149659863946\n"
     ]
    }
   ],
   "source": [
    "location = 'wine-quality/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "#print(test)\n",
    "testcopy = test.copy()\n",
    "traincopy = train.copy()\n",
    "target = 'quality'\n",
    "unique_class = np.unique(np.array(train[target]))\n",
    "labpred = []\n",
    "labdict = {}\n",
    "true_predicted = []\n",
    "z = 0\n",
    "for key in unique_class:\n",
    "    labdict[z] = key\n",
    "    z+=1\n",
    "print(labdict)\n",
    "for c in unique_class:\n",
    "    train[target] = (train[target].values) == c\n",
    "    test[target] = (test[target].values) == c\n",
    "    slopeValues = LogisticRegressionFit(dataframe,test,train,target)\n",
    "    #print(slopeValues)\n",
    "    X,predicted_y = predictLinear(dataframe,test,target,slopeValues,True)\n",
    "    labpred.append(predicted_y)\n",
    "    train = traincopy.copy()\n",
    "    test = testcopy.copy()\n",
    "    #print(predicted_y)\n",
    "    #print(test[target].values)\n",
    "labpred = np.array(labpred)\n",
    "#print(labpred)\n",
    "for row in range(0,len(testcopy[target])):\n",
    "    true_predicted.append(labdict[(np.argmax(labpred[:,row]))])\n",
    "#print(true_predicted)\n",
    "#print(testcopy[target])\n",
    "accuracy,precision,recall = BinaryMeasure(true_predicted,testcopy,target,True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5272108843537415\n"
     ]
    }
   ],
   "source": [
    "location = 'wine-quality/data.csv'\n",
    "dataframe,test,train = get_test_train_with_header(location)\n",
    "#print(test)\n",
    "testcopy = test.copy()\n",
    "traincopy = train.copy()\n",
    "target = 'quality'\n",
    "unique_class = np.unique(np.array(train[target]))\n",
    "labpred = []\n",
    "labdict = {}\n",
    "true_predicted = []\n",
    "z = 0\n",
    "for key in unique_class:\n",
    "    labdict[z] = key\n",
    "    z+=1\n",
    "    \n",
    "for c1_ind in range(0,len(unique_class)):\n",
    "    for c2_ind in range(c1_ind,len(unique_class)):\n",
    "        if unique_class[c1_ind]!=unique_class[c2_ind]:\n",
    "            train = train[(train[target] == unique_class[c1_ind]) | (train[target] == unique_class[c2_ind])]\n",
    "            train = test[(test[target] == unique_class[c1_ind]) | (test[target] == unique_class[c2_ind])]\n",
    "            #print(train)\n",
    "            train[target] = (train[target].values) == unique_class[c1_ind]\n",
    "            test[target] = (test[target].values) == unique_class[c1_ind]\n",
    "            slopeValues = LogisticRegressionFit(dataframe,test,train,target)\n",
    "            X,predicted_y = predictLinear(dataframe,test,target,slopeValues,True)\n",
    "            for val in range(0,len(predicted_y)):\n",
    "                if predicted_y[val] >= 0.5:\n",
    "                    predicted_y[val] = unique_class[c1_ind]\n",
    "                else:\n",
    "                    predicted_y[val] = unique_class[c2_ind]\n",
    "            labpred.append(predicted_y)\n",
    "            train = traincopy.copy()\n",
    "            test = testcopy.copy()\n",
    "            #print(predicted_y)\n",
    "            #print(test[target].values)\n",
    "labpred = np.array(labpred)\n",
    "predarr = []\n",
    "for row in range(0,len(testcopy[target])):\n",
    "    #print(row)\n",
    "    col = []\n",
    "    col.extend(labpred[:,row])\n",
    "    count = max(col,key=col.count)\n",
    "    true_predicted.append(count)\n",
    "    #true_predicted.append(labdict[(np.argmax(labpred[:,row]))]) \n",
    "accuracy,precision,recall = BinaryMeasure(true_predicted,testcopy,target,True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
